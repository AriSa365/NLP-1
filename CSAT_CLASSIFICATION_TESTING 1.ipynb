{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cd5e44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertForSequenceClassification\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"C:\\\\Users\\\\2151399\\\\OneDrive - Cognizant\\\\Desktop\\\\nlp_project\\\\CSAT_senti_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1350cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"C:\\\\Users\\\\2151399\\\\OneDrive - Cognizant\\\\Desktop\\\\nlp_project\\\\CSAT_senti_model\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdd5d280",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "pipe = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "448221f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2151399\\Anaconda3\\lib\\site-packages\\gradio\\blocks.py:675: UserWarning: api_name predict already exists, using predict_1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\2151399\\AppData\\Local\\Temp\\ipykernel_17576\\916948802.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(df2, ignore_index = True)\n",
      "C:\\Users\\2151399\\AppData\\Local\\Temp\\ipykernel_17576\\916948802.py:18: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(df2, ignore_index = True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "\n",
    "\n",
    "def durgPercentage(gData):\n",
    "    df = pd.DataFrame()\n",
    "    s_no = 1\n",
    "    for drugs in gData:\n",
    "        score = gData[drugs]\n",
    "        positive = score[2] * 2\n",
    "        per = round(((score[1] + positive)/(score[3]*2)) *100 ,2)\n",
    "        strPer = str(per)\n",
    "        strPer = strPer + \" %\"\n",
    "        df2 = {'S_no': s_no, 'DrugName': drugs, 'Review Percentage': strPer}\n",
    "        df = df.append(df2, ignore_index = True)\n",
    "        s_no = s_no + 1\n",
    "\n",
    "    return df\n",
    "    \n",
    "\n",
    "\n",
    "# Group by processing\n",
    "def GroupBy(data_frame):\n",
    "    gData = {}\n",
    "    for i, j in data_frame.iterrows():\n",
    "        drug_name = j['drugName']\n",
    "        prediction = j['Prediction']\n",
    "        positive = 0\n",
    "        neutral = 0\n",
    "        negative = 0\n",
    "        length = 0\n",
    "\n",
    "    if drug_name in gData:\n",
    "        if prediction == \"positive\":\n",
    "            positive = gData[drug_name][2]\n",
    "            neutral = gData[drug_name][1]\n",
    "            negative = gData[drug_name][0]\n",
    "            positive = positive + 1\n",
    "            length = gData[drug_name][3]\n",
    "            length = length + 1\n",
    "            gData[drug_name] = [negative, neutral, positive, length]\n",
    "        elif prediction == \"neutral\":\n",
    "            positive = gData[drug_name][2]\n",
    "            neutral = gData[drug_name][1]\n",
    "            negative = gData[drug_name][0]\n",
    "            neutral = neutral + 1\n",
    "            length = gData[drug_name][3]\n",
    "            length = length + 1\n",
    "            gData[drug_name] = [negative, neutral, positive, length]\n",
    "        elif prediction == \"negative\":\n",
    "            positive = gData[drug_name][2]\n",
    "            neutral = gData[drug_name][1]\n",
    "            negative = gData[drug_name][0]\n",
    "            negative = negative + 1\n",
    "            length = gData[drug_name][3]\n",
    "            length = length + 1\n",
    "            gData[drug_name] = [negative, neutral, positive, length]\n",
    "    else:\n",
    "        if prediction == \"positive\":\n",
    "            gData[drug_name] = [0, 0, 1, 1]\n",
    "        elif prediction == \"neutral\":\n",
    "             gData[drug_name] = [0, 1, 0, 1]\n",
    "        elif prediction == \"negative\":\n",
    "            gData[drug_name] = [1, 0, 0, 1]\n",
    "\n",
    "\n",
    "    df = durgPercentage(gData)\n",
    "    return df\n",
    "\n",
    "\n",
    " #TEXT TO TEXT FUNCTION\n",
    "def greet(user_input):\n",
    "    output = pipe(user_input)\n",
    "    final = str(output[0].get('label'))\n",
    "    score = str(round((output[0].get('score') * 100), 2))\n",
    "    return final, score + \" %\"\n",
    "\n",
    "\n",
    "\n",
    "#FILE TO FILE FUNCTION\n",
    "def filee(files):\n",
    "    k = 1000\n",
    "    d = pd.read_csv(files[0].name)\n",
    "    listOfPrediction = []\n",
    "    listofProbability =[]\n",
    "    for i, j in d.iterrows():\n",
    "        if k==0:\n",
    "            break\n",
    "        user_input = str(j[\"review\"])\n",
    "        text = user_input\n",
    "        cut_str = text[:400]\n",
    "\n",
    "        k = k-1\n",
    "        output = pipe(cut_str)\n",
    "        final = str(output[0].get('label'))\n",
    "        score = str(round((output[0].get('score') * 100), 2))\n",
    "        listOfPrediction.append(final)\n",
    "        listofProbability.append(score)\n",
    "\n",
    "\n",
    "    df = pd.read_csv(files[0].name, sep=\",\",names=['uniqueid','drugName','review'],skiprows=[0],usecols=[0,1,3],header=None,encoding='utf-8',low_memory=False)\n",
    "    df = df.head(1000)\n",
    "    df['Prediction'] = listOfPrediction \n",
    "    df['Probability']= listofProbability\n",
    "    finalDf = GroupBy(df)\n",
    "    csv_data = df.to_csv(path_or_buf=files[0].name,sep=',')\n",
    "    finalDf = GroupBy(df)\n",
    "\n",
    "    return files[0].name,finalDf\n",
    "\n",
    "#GRADIO INTERFACE:   \n",
    "\n",
    "iface = gr.Interface(fn=greet, inputs=\"text\", outputs=[gr.Textbox(label=\"CSAT_ANALYSIS\"),gr.Textbox(label=\"CSAT_SCORE\")])\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=filee,\n",
    "    inputs=[gr.Files(label='user_input',file_count=\"multiple\", file_types=[\"text\", \".json\", \".csv\",\".xlsx\"])],\n",
    "    outputs=[gr.Files(label='predicted_output'),gr.Dataframe(label='predicted_output',max_rows=None,max_cols=None)]\n",
    "    ) \n",
    "\n",
    "g=gr.TabbedInterface([iface,demo],[\"Single Input-Single Output\",\"Batch-Prediction\"])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    g.launch(debug=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ebf0c85f",
   "metadata": {},
   "source": [
    "import time \n",
    "from tqdm import tqdm_notebook\n",
    "from transformers import DistilBertForSequenceClassification\n",
    "\n",
    "for i in tqdm_notebook(range(10)):\n",
    "    \n",
    "    model = DistilBertForSequenceClassification.from_pretrained(\"C:\\\\Users\\\\2151399\\\\OneDrive - Cognizant\\\\Desktop\\\\nlp_project\\\\CSAT_senti_model\")\n",
    "\n",
    "    time.sleep(0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
